{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDS UC Berkeley, Machine Learning at Scale\n",
    "## DATSCIW261 ASSIGNMENT #1  \n",
    "\n",
    "James Gray | jamesgray@ischool.berkeley.edu\n",
    "\n",
    "Date Submitted: May x, 2016\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.0.0. \n",
    "\n",
    "Define big data. Provide an example of a big data problem in your domain of expertise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, Big Data is defined as data that are so large, complex and speed that traditional applications are not adequate to deliver solutions.  Big Data is often described by three or four V's.  Volume often distinquishes Big Data as datasets that reach the petabyte (10^15) or zettbyte (10^21) scale when compared to traditional data processing applications in the terabytes (10^12). Variety includes both structured and unstructed data such as video, text, JSON, images unlike traditional systems that handled well formed data in rows and columns. Velocity includes the ability of Big Data solutions to handle very fast streaming data from sources such as the social web or machine-to-machine scenarios in the Internet of Things realm.  Veracity is the uncertainty of data and ability to manage and enforce data quality.  All of these attributes make traditional data processing systems such as databases completely inadequate.\n",
    "\n",
    "Example here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.0.1.\n",
    "\n",
    "In 500 words (English or pseudo code or a combination) describe how to estimate the bias, the variance, the irreduciable error for a test dataset T when using polynomial regression models of degree 1,2,3,4,5 are considered. How would you select a model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions for Spam Filter using Naive Bayes Classifier\n",
    "\n",
    "In the remainder of this assignment you will produce a spam filter that is backed by a multinomial naive Bayes classifier b (see http://nlp.stanford.edu/IR-book/html/htmledition/properties-of-naive-bayes-1.html),\n",
    "which counts words in parallel via a unix, poor-man's map-reduce framework.  \n",
    "\n",
    "The data you will use is a curated subset of the Enron email corpus(whose details you may find in the file enronemail_README.txt in the directory surrounding these instructions).\n",
    "\n",
    "In this directory you will also find starter code (pNaiveBayes.sh),(similar to the pGrepCount.sh code that was presented in this weeks lectures), which will be used as control script to a python mapper and reducer that you will supply at several stages. Doing some exploratory data analysis you will see (with this very small dataset) the following\\:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      99 enronemail_1h.txt\n",
      "     100     100     200\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0018.2003-12-18.GP      1        await your response    \" dear partner,  we are  \ba team of government officials that belong to an eight-man committee in the pres \bidential cabinet as well as the senate.  at the moment, we will be requiring you \br assistance in a matter that involves investment of monies, which we intend to  \btransfer to your account, upon clarification and a workable agreement reached in \b consummating the project with you. based on a recommendation from an associate  \bconcerning your integrity, loyalty and understanding, we deemed it necessary to  \bcontact you accordingly. all arrangements in relation to this investment initiat \bive, as well as the initial capital for its take off has been tactically set asi \bde to commence whatever business you deemed fit, that will turn around profit fa \bvourably. we request you immediately contact us if you will be favorably dispose \bd to act as a partner in this venture, and possibly will afford us the opportuni \bty to discuss whatever proposal you may come up with. also  bear in mind that th \be initial capital that we shall send across will not exceed$ 13,731, 000,00 usd  \b(thirteen million seven hundred and thirty one thousand united states dollars) s \bo whatever areas of investment your proposal shall cover, please it should be wi \bthin the set aside capital. in this regard, the proposal you may wish to discuss \b with us should be comprehensive enough for our better understanding; with speci \bal emphasis on the following:  1. the tax obligationin your country  2. the init \bial capital base required in your proposed  investment area, as well as;  3. the \b legal technicalities in setting up a  business in your country with foreigners  \bas share-holders  4. the most convenient and secured mode of receiving the funds \b without our direct involvement.  5. your ability to provide a beneficiary/partn \b:\u001b[K"
     ]
    }
   ],
   "source": [
    "! wc -l enronemail_1h.txt  #100 email records\n",
    "\n",
    "! cut -f2 -d$'\\t' enronemail_1h.txt|wc  #extract second field which is SPAM flag\n",
    "\n",
    "! cut -f2 -d$'\\t' enronemail_1h.txt|head\n",
    "\n",
    "! head -n 100 enronemail_1h.txt|tail -1|less #an example SPAM email record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.1.\n",
    "\n",
    "Read through the provided control script (pNaiveBayes.sh) and all of its comments. When you are comfortable with their purpose and function, respond to the remaining homework questions below. A simple cell in the notebook with a print statement with  a \"done\" string will suffice here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## pNaiveBayes.sh\n",
    "## Author: Jake Ryland Williams\n",
    "## Usage: pNaiveBayes.sh m wordlist\n",
    "## Input:\n",
    "##       m = number of processes (maps), e.g., 4\n",
    "##       wordlist = a space-separated list of words in quotes, e.g., \"the and of\"\n",
    "##\n",
    "## Instructions: Read this script and its comments closely.\n",
    "##               Do your best to understand the purpose of each command,\n",
    "##               and focus on how arguments are supplied to mapper.py/reducer.py,\n",
    "##               as this will determine how the python scripts take input.\n",
    "##               When you are comfortable with the unix code below,\n",
    "##               answer the questions on the LMS for HW1 about the starter code.\n",
    "\n",
    "## collect user input\n",
    "m=$1 ## the number of parallel processes (maps) to run\n",
    "wordlist=$2 ## if set to \"*\", then all words are used\n",
    "\n",
    "## a test set data of 100 messages\n",
    "data=\"enronemail_1h.txt\" \n",
    "\n",
    "## the full set of data (33746 messages)\n",
    "# data=\"enronemail.txt\" \n",
    "\n",
    "## 'wc' determines the number of lines in the data\n",
    "## 'perl -pe' regex strips the piped wc output to a number\n",
    "linesindata=`wc -l $data | perl -pe 's/^.*?(\\d+).*?$/$1/'`\n",
    "\n",
    "## determine the lines per chunk for the desired number of processes\n",
    "linesinchunk=`echo \"$linesindata/$m+1\" | bc` \n",
    "\n",
    "## split the original file into chunks by line\n",
    "split -l $linesinchunk $data $data.chunk.\n",
    "\n",
    "## assign python mappers (mapper.py) to the chunks of data\n",
    "## and emit their output to temporary files\n",
    "for datachunk in $data.chunk.*; do\n",
    "    ## feed word list to the python mapper here and redirect STDOUT to a temporary file on disk\n",
    "    ####\n",
    "    ####\n",
    "    ./mapper.py $datachunk \"$wordlist\" > $datachunk.counts &\n",
    "    ####\n",
    "    ####\n",
    "done\n",
    "## wait for the mappers to finish their work\n",
    "wait\n",
    "\n",
    "## 'ls' makes a list of the temporary count files\n",
    "## 'perl -pe' regex replaces line breaks with spaces\n",
    "countfiles=`\\ls $data.chunk.*.counts | perl -pe 's/\\n/ /'`\n",
    "\n",
    "## feed the list of countfiles to the python reducer and redirect STDOUT to disk\n",
    "####\n",
    "####\n",
    "./reducer.py $countfiles > $data.output\n",
    "####\n",
    "####\n",
    "\n",
    "## clean up the data chunks and temporary count files\n",
    "\\rm $data.chunk.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.2. \n",
    "\n",
    "Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh will determine the number of occurrences of a single, user-specified word. Examine the word “assistance” and report your results.  To do so, make sure that:\n",
    "   \n",
    "* mapper.py counts all occurrences of a single word, and\n",
    "* reducer.py collates the counts of the single word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.3. \n",
    "\n",
    "Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh will classify the email messages by a single, user-specified word using the multinomial Naive Bayes Formulation. Examine the word “assistance” and report your results.\n",
    "   \n",
    "To do so, make sure that:\n",
    "   \n",
    "   - mapper.py and\n",
    "   - reducer.py \n",
    "\n",
    "performs a single word Naive Bayes classification. For multinomial Naive Bayes, the Pr(X=“assistance”|Y=SPAM) is calculated as follows:\n",
    "\n",
    "the number of times “assistance” occurs in SPAM labeled documents / the number of words in documents labeled SPAM \n",
    "\n",
    "NOTE if  “assistance” occurs 5 times in all of the documents Labeled SPAM, and the length in terms of the number of words in all documents labeld as SPAM (when concatenated) is 1,000. Then Pr(X=“assistance”|Y=SPAM) = 5/1000. Note this is a multinomial estimated of the class conditional for a Naive Bayes Classifier. No smoothing is needed in this HW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.4. \n",
    "\n",
    "Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh will classify the email messages by a list of one or more user-specified words.\n",
    "\n",
    "Examine the words “assistance”, “valium”, and “enlargementWithATypo” and report your results (accuracy). To do so, make sure that:\n",
    "\n",
    "* mapper.py counts all occurrences of a list of words, and\n",
    "* reducer.py \n",
    "\n",
    "performs the multiple-word multinomial Naive Bayes classification via the chosen list. No smoothing is needed in this HW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.5. \n",
    "\n",
    "Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh will classify the email messages by all words present.\n",
    "\n",
    "To do so, make sure that:\n",
    "\n",
    "* mapper.py counts all occurrences of all words, and\n",
    "* reducer.py performs a word-distribution-wide Naive Bayes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.6 \n",
    "\n",
    "Benchmark your code with the Python SciKit-Learn implementation of multinomial Naive Bayes.\n",
    "\n",
    "It always a good idea to test your solutions against publicly available libraries such as SciKit-Learn, The Machine Learning toolkit available in Python. In this exercise, we benchmark ourselves against the SciKit-Learn implementation of multinomial Naive Bayes.  For more information on this implementation see: http://scikit-learn.org/stable/modules/naive_bayes.html more  \n",
    "\n",
    "Training error = misclassification rate with respect to a training set. It is more formally defined here:\n",
    "\n",
    "Let DF represent the training set in the following:\n",
    "Err(Model, DF) = |{(X, c(X)) ∈ DF : c(X) != Model(x)}|   / |DF|\n",
    "\n",
    "Where || denotes set cardinality; c(X) denotes the class of the tuple X in DF; and Model(X) denotes the class inferred by the Model “Model”\n",
    "\n",
    "In this exercise, please complete the following:\n",
    "\n",
    "* Run the Multinomial Naive Bayes algorithm (using default settings) from SciKit-Learn over the same training data used in HW1.5 and report the Training error (please note some data preparation might be needed to get the Multinomial Naive Bayes algorithm from SkiKit-Learn to run over this dataset)\n",
    "* Please prepare a table to present your results\n",
    "* Explain/justify any differences in terms of training error rates over the dataset in HW1.5 between your Multinomial Naive Bayes implementation (in Map Reduce) versus the Multinomial Naive Bayes implementation in SciKit-Learn (Hint: smoothing, which we will discuss in next lecture)\n",
    "* Discuss the performance differences in terms of training error rates over the dataset in HW1.5 between the  Multinomial Naive Bayes implementation in SciKit-Learn with the  Bernoulli Naive Bayes implementation in SciKit-Learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
