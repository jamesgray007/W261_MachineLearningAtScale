{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS UC Berkeley - Machine Learning at Scale\n",
    "## DATSCIW261 ASSIGNMENT #4  \n",
    "\n",
    "[James Gray](https://github.com/jamesgray007)   \n",
    "jamesgray@ischool.berkeley.edu   \n",
    "Time of Initial Submission: 08:21 PM US Central, Friday, June 10, 2016  \n",
    "Time of **Resubmission**:  \n",
    "W261-1, Spring 2016  \n",
    "Week 4 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References for this Assignment\n",
    "\n",
    "* [Python Hosted Documentation](https://pythonhosted.org/mrjob/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install mrjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4.0\n",
    "\n",
    "**_What is MrJob? How is it different to Hadoop MapReduce?_**\n",
    "\n",
    "[MRJob](https://pythonhosted.org/mrjob/index.html) is a programming framework to execute Hadoop Streaming jobs using Python. It was developed by Yelp in 2010 to enable parallel processing of log files. One of the primary motivations of MRJob is enable easy programming and execution of jobs with multiple steps or iterations all from one program. This enables coding and execution of complex data processing pipelines from one encapsulated code module. MRJob can be executed locally (laptop), cluster and has easy integration with AWS Elastic MapReduce.\n",
    "\n",
    "In contrast to Hadoop MapReduce, individual code modules (e.g., mappers, reducers) are distributed off to the cluster machines unlike the MRJob code which is a class that contains all of the mapper and reducer logic. It is more difficult to orchestrate pipelines with multiple iterations and jobs in pure Hadoop MapReduce.\n",
    "\n",
    "**_What are the mapper_init, mapper_final(), combiner_final(), reducer_final() methods? When are they called?_**\n",
    "\n",
    "All of the MRJob code is written in one class (a subclass of MRJob) and these methods provide additional control prior and post execution of the mapper and reduce code. Quite often you will want to run initialization tasks such as reading a file prior to executing the mapper and reduce code and this is the purpose of the mapper_init method.  You may also want to operations such as writing files and running clean-up routines after the mapper and reduce code has processed and this is the purpose of the mapper_final and reducer_final methods.  These _init and _final methods give rich control to the programmer to run pre and post operations that would be difficult to achieve in pure Hadoop MapReduce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4.1\n",
    "\n",
    "**_What is serialization in the context of MrJob or Hadoop?_**\n",
    "\n",
    "Serialization is the process of translating data structures or object state into a format that can be stored (for example, in a file or memory buffer, or transmitted across a network connection link) and reconstructed later in the same or another computer environment ([Wikipedia](https://en.wikipedia.org/wiki/Serialization)). Deserialization is the reverse process of turning a byte stream into structured objects. \n",
    "\n",
    "Serialization is used in two distinct areas of distributed data processing:\n",
    "* Interprocess communication\n",
    "* Persistent storage\n",
    "\n",
    "**_When it used in these frameworks?_**\n",
    "\n",
    "In the context of MRJob and Hadoop, serialization is used to turn structured objects into a byte stream and transmit these over the network to cluster machines.  The binary format is much more efficient for storing and transmitting data than raw text data.\n",
    "\n",
    "**_What is the default serialization mode for input and outputs for MrJob?_** \n",
    "\n",
    "The default mode for MRJob input data is raw text data and the output format is JSON. MRJob uses JSON protocol for internal transmission between processes or steps. MRJob has default and other protocols that are available:\n",
    "\n",
    "Defaults\n",
    "* INPUT_PROTOCOL = mrjob.protocol.RawValueProtocol\n",
    "* INTERNAL_PROTOCOL = mrjob.protocol.JSONProtocol\n",
    "* OUTPUT_PROTOCOL = mrjob.protocol.JSONProtocol\n",
    "\n",
    "Available\n",
    "* RawProtocol / RawValueProtocol\n",
    "* JSONProtocol / JSONValueProtocol\n",
    "* PickleProtocol / PickleValueProtocol\n",
    "* ReprProtocol / ReprValueProtocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.2 - Microsoft Logfiles\n",
    "\n",
    "Recall the Microsoft logfiles data from the async lecture. The logfiles are described are located at:\n",
    "\n",
    "https://kdd.ics.uci.edu/databases/msweb/msweb.html\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/anonymous/\n",
    "\n",
    "This dataset records which areas (Vroots) of www.microsoft.com each user visited in a one-week timeframe in Feburary 1998.\n",
    "\n",
    "Here, you must preprocess the data on a single node (i.e., not on a cluster of nodes) **from the format:**\n",
    "\n",
    "C,\"10001\",10001    #Visitor id 10001  \n",
    "V,1000,1           #Visit by Visitor 10001 to page id 1000  \n",
    "V,1001,1           #Visit by Visitor 10001 to page id 1001  \n",
    "V,1002,1           #Visit by Visitor 10001 to page id 1002  \n",
    "C,\"10002\",10002    #Visitor id 10001  \n",
    "\n",
    "**to the format:**\n",
    "\n",
    "V,1000,1,C,10001  \n",
    "V,1001,1,C,10001  \n",
    "V,1002,1,C,10001\n",
    "\n",
    "Write the python code to accomplish this.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.2 - Log File Transformation\n",
    "\n",
    "The code below processes each line of the raw logfile data and transforms the data into the defined format above.  The structure of the file is consistent with the visitor ID first and then a record for each web page visited.  This new format will be used by MRJob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting process_logfile.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile process_logfile.py\n",
    "#!/usr/bin/python\n",
    "## logfile.py\n",
    "## Author: James Gray\n",
    "## Description: convert raw log file dataset into new defined format\n",
    "\n",
    "# open CSV file\n",
    "from csv import reader\n",
    "with open('anonymous-msweb.data','rb') as f:\n",
    "    data=f.readlines()\n",
    "    \n",
    "for i in reader(data):\n",
    "    if i[0]=='C':\n",
    "        visitor_id=i[1] #Store visitor id\n",
    "        continue\n",
    "    if i[0]=='V':\n",
    "        print i[0]+','+i[1]+','+i[2]+',C,'+visitor_id #Append visitor_id to each pageview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V,1000,1,C,10001\r\n",
      "V,1001,1,C,10001\r\n",
      "V,1002,1,C,10001\r\n",
      "V,1001,1,C,10002\r\n",
      "V,1003,1,C,10002\r\n",
      "V,1001,1,C,10003\r\n",
      "V,1003,1,C,10003\r\n",
      "V,1004,1,C,10003\r\n",
      "V,1005,1,C,10004\r\n",
      "V,1006,1,C,10005\r\n",
      "cat: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# let's test the script file to ensure we properly converting the data\n",
    "!chmod a+x process_logfile.py\n",
    "\n",
    "!python process_logfile.py > ms_logs.txt\n",
    "!cat ms_logs.txt | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.3 - Top Five Pages\n",
    "\n",
    "Find the 5 most frequently visited pages using MrJob from the output of 4.2 (i.e., transfromed log file). This code is similar to the standard word count example but there is a 2nd reducer step that operates as a sort function using:\n",
    "\n",
    "mapreduce.partition.keycomparator.options': '-k2,2nr -k1,1'\n",
    "\n",
    "that will sort the reducer output by page views (2nd field) and then web page ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Use this to make sure we reload the MrJob code when we make changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing TopFivePages.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile TopFivePages.py\n",
    "from mrjob.job import MRJob\n",
    "#from mrjob.step import MRJobStep\n",
    "from mrjob.step import MRStep\n",
    "import csv\n",
    "\n",
    "def csv_readline(line):\n",
    "    \"\"\"Given a sting CSV line, return a list of strings.\"\"\"\n",
    "    for row in csv.reader([line]):\n",
    "        return row\n",
    "\n",
    "class MRGetTopFive(MRJob):\n",
    "\n",
    "    def mapper_count_visits(self, _, line):\n",
    "        record = csv_readline(line)\n",
    "        if record[0] == 'V':\n",
    "            yield record[1], 1\n",
    "    \n",
    "    def reducer_sum_visits(self, page_id, counts):\n",
    "        yield page_id, sum(counts)\n",
    "    \n",
    "    def reducer_sort_visits(self, page_id, counts):\n",
    "        yield page_id, sum(counts)\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP2 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'stream.num.map.output.key.field': 2,\n",
    "            'stream.map.output.field.separator':',',\n",
    "            'mapreduce.partition.keycomparator.options': '-k2,2nr -k1,1',\n",
    "            'mapreduce.job.reduces': '1',\n",
    "        }\n",
    "        return [\n",
    "            self.mr(mapper=self.mapper_count_visits,   # STEP 1:  count the visits\n",
    "                   reducer=self.reducer_sum_visits),\n",
    "            self.mr(jobconf=JOBCONF_STEP2,\n",
    "                    reducer=self.reducer_sort_visits)  # STEP 2:  sort the visits\n",
    "        ]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRGetTopFive.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set file priveleges\n",
    "!chmod a+x TopFivePages.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.3 - Execute MRJob from Command Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/TopFivePages.hadoop.20160610.224207.600433\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.7.2\n",
      "Copying local files to hdfs:///user/hadoop/tmp/mrjob/TopFivePages.hadoop.20160610.224207.600433/files/...\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop/hadoop-streaming-2.7.2-amzn-1.jar] /tmp/streamjob3958455242306075430.jar tmpDir=null\n",
      "  Connecting to ResourceManager at ip-172-31-7-251.us-west-1.compute.internal/172.31.7.251:8032\n",
      "  Connecting to ResourceManager at ip-172-31-7-251.us-west-1.compute.internal/172.31.7.251:8032\n",
      "  MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: true maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1464726748890 \n",
      "  Created MetricsSaver j-ZAC3GQDMC0E6:i-610a91d4:RunJar:00559 period:60 /mnt/var/em/raw/i-610a91d4_20160610_RunJar_00559_raw.bin\n",
      "  Loaded native gpl library\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev 426d94a07125cf9447bb0c2b336cf10b4c254375]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:16\n",
      "  Submitting tokens for job: job_1464726740139_0040\n",
      "  Submitted application application_1464726740139_0040\n",
      "  The url to track the job: http://ip-172-31-7-251.us-west-1.compute.internal:20888/proxy/application_1464726740139_0040/\n",
      "  Running job: job_1464726740139_0040\n",
      "  Job job_1464726740139_0040 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 29%\n",
      "   map 100% reduce 57%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1464726740139_0040 completed successfully\n",
      "  Output directory: hdfs:///user/hadoop/tmp/mrjob/TopFivePages.hadoop.20160610.224207.600433/step-output/0000\n",
      "Counters: 52\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2067286\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2903\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=53107\n",
      "\t\tFILE: Number of bytes written=3131796\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2070326\n",
      "\t\tHDFS: Number of bytes written=2903\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=69\n",
      "\t\tHDFS: Number of write operations=14\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=8\n",
      "\t\tKilled map tasks=1\n",
      "\t\tKilled reduce tasks=1\n",
      "\t\tLaunched map tasks=16\n",
      "\t\tLaunched reduce tasks=7\n",
      "\t\tRack-local map tasks=8\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=273931200\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=190736640\n",
      "\t\tTotal time spent by all map tasks (ms)=190230\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=8560350\n",
      "\t\tTotal time spent by all reduce tasks (ms)=66228\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=5960520\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=190230\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=66228\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=44810\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=3152\n",
      "\t\tInput split bytes=3040\n",
      "\t\tMap input records=98654\n",
      "\t\tMap output bytes=887886\n",
      "\t\tMap output materialized bytes=71220\n",
      "\t\tMap output records=98654\n",
      "\t\tMerged Map outputs=112\n",
      "\t\tPhysical memory (bytes) snapshot=8652480512\n",
      "\t\tReduce input groups=285\n",
      "\t\tReduce input records=98654\n",
      "\t\tReduce output records=285\n",
      "\t\tReduce shuffle bytes=71220\n",
      "\t\tShuffled Maps =112\n",
      "\t\tSpilled Records=197308\n",
      "\t\tTotal committed heap usage (bytes)=10237247488\n",
      "\t\tVirtual memory (bytes) snapshot=56034516992\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/usr/lib/hadoop/hadoop-streaming-2.7.2-amzn-1.jar] /tmp/streamjob4395671309790786008.jar tmpDir=null\n",
      "  Connecting to ResourceManager at ip-172-31-7-251.us-west-1.compute.internal/172.31.7.251:8032\n",
      "  Connecting to ResourceManager at ip-172-31-7-251.us-west-1.compute.internal/172.31.7.251:8032\n",
      "  MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: true maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1464726748890 \n",
      "  Created MetricsSaver j-ZAC3GQDMC0E6:i-610a91d4:RunJar:00833 period:60 /mnt/var/em/raw/i-610a91d4_20160610_RunJar_00833_raw.bin\n",
      "  Loaded native gpl library\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev 426d94a07125cf9447bb0c2b336cf10b4c254375]\n",
      "  Total input paths to process : 7\n",
      "  number of splits:21\n",
      "  Submitting tokens for job: job_1464726740139_0041\n",
      "  Submitted application application_1464726740139_0041\n",
      "  The url to track the job: http://ip-172-31-7-251.us-west-1.compute.internal:20888/proxy/application_1464726740139_0041/\n",
      "  Running job: job_1464726740139_0041\n",
      "  Job job_1464726740139_0041 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1464726740139_0041 completed successfully\n",
      "  Output directory: hdfs:///user/hadoop/tmp/mrjob/TopFivePages.hadoop.20160610.224207.600433/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4908\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2903\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1949\n",
      "\t\tFILE: Number of bytes written=2892518\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=9108\n",
      "\t\tHDFS: Number of bytes written=2903\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=66\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=20\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=21\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=411121440\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=33698880\n",
      "\t\tTotal time spent by all map tasks (ms)=285501\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=12847545\n",
      "\t\tTotal time spent by all reduce tasks (ms)=11701\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1053090\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=285501\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=11701\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=25270\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=4046\n",
      "\t\tInput split bytes=4200\n",
      "\t\tMap input records=285\n",
      "\t\tMap output bytes=3188\n",
      "\t\tMap output materialized bytes=3127\n",
      "\t\tMap output records=285\n",
      "\t\tMerged Map outputs=21\n",
      "\t\tPhysical memory (bytes) snapshot=9137577984\n",
      "\t\tReduce input groups=285\n",
      "\t\tReduce input records=285\n",
      "\t\tReduce output records=285\n",
      "\t\tReduce shuffle bytes=3127\n",
      "\t\tShuffled Maps =21\n",
      "\t\tSpilled Records=570\n",
      "\t\tTotal committed heap usage (bytes)=10927210496\n",
      "\t\tVirtual memory (bytes) snapshot=46330814464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/hadoop/tmp/mrjob/TopFivePages.hadoop.20160610.224207.600433/output...\n",
      "\"1008\"\t10836\n",
      "\"1034\"\t9383\n",
      "\"1004\"\t8463\n",
      "\"1018\"\t5330\n",
      "\"1017\"\t5108\n",
      "\"1009\"\t4628\n",
      "\"1001\"\t4451\n",
      "\"1026\"\t3220\n",
      "\"1003\"\t2968\n",
      "\"1025\"\t2123\n",
      "\"1035\"\t1791\n",
      "\"1040\"\t1506\n",
      "\"1041\"\t1500\n",
      "\"1032\"\t1446\n",
      "\"1037\"\t1160\n",
      "\"1030\"\t1115\n",
      "\"1038\"\t1110\n",
      "\"1020\"\t1087\n",
      "\"1000\"\t912\n",
      "\"1007\"\t865\n",
      "\"1052\"\t842\n",
      "\"1036\"\t759\n",
      "\"1002\"\t749\n",
      "\"1014\"\t728\n",
      "\"1295\"\t716\n",
      "\"1010\"\t698\n",
      "\"1058\"\t672\n",
      "\"1053\"\t670\n",
      "\"1046\"\t636\n",
      "\"1070\"\t602\n",
      "\"1074\"\t584\n",
      "\"1031\"\t574\n",
      "\"1067\"\t548\n",
      "\"1024\"\t521\n",
      "\"1027\"\t507\n",
      "\"1045\"\t474\n",
      "\"1078\"\t462\n",
      "\"1076\"\t444\n",
      "\"1075\"\t396\n",
      "\"1130\"\t395\n",
      "\"1060\"\t391\n",
      "\"1021\"\t380\n",
      "\"1123\"\t372\n",
      "\"1119\"\t365\n",
      "\"1039\"\t345\n",
      "\"1049\"\t343\n",
      "\"1054\"\t338\n",
      "\"1022\"\t325\n",
      "\"1064\"\t324\n",
      "\"1065\"\t323\n",
      "\"1100\"\t291\n",
      "\"1016\"\t287\n",
      "\"1042\"\t281\n",
      "\"1056\"\t276\n",
      "\"1061\"\t269\n",
      "\"1055\"\t264\n",
      "\"1059\"\t258\n",
      "\"1082\"\t241\n",
      "\"1088\"\t237\n",
      "\"1069\"\t227\n",
      "\"1043\"\t224\n",
      "\"1124\"\t222\n",
      "\"1081\"\t215\n",
      "\"1096\"\t214\n",
      "\"1048\"\t210\n",
      "\"1073\"\t204\n",
      "\"1125\"\t199\n",
      "\"1068\"\t198\n",
      "\"1057\"\t195\n",
      "\"1023\"\t191\n",
      "\"1087\"\t189\n",
      "\"1071\"\t187\n",
      "\"1084\"\t186\n",
      "\"1105\"\t183\n",
      "\"1113\"\t181\n",
      "\"1136\"\t181\n",
      "\"1011\"\t179\n",
      "\"1118\"\t172\n",
      "\"1044\"\t168\n",
      "\"1183\"\t167\n",
      "\"1134\"\t162\n",
      "\"1089\"\t157\n",
      "\"1077\"\t155\n",
      "\"1131\"\t148\n",
      "\"1062\"\t141\n",
      "\"1079\"\t136\n",
      "\"1006\"\t135\n",
      "\"1029\"\t132\n",
      "\"1127\"\t132\n",
      "\"1072\"\t128\n",
      "\"1112\"\t128\n",
      "\"1157\"\t124\n",
      "\"1137\"\t123\n",
      "\"1080\"\t121\n",
      "\"1099\"\t120\n",
      "\"1102\"\t118\n",
      "\"1140\"\t118\n",
      "\"1135\"\t115\n",
      "\"1063\"\t113\n",
      "\"1019\"\t111\n",
      "\"1090\"\t107\n",
      "\"1050\"\t106\n",
      "\"1083\"\t105\n",
      "\"1095\"\t102\n",
      "\"1098\"\t98\n",
      "\"1092\"\t97\n",
      "\"1148\"\t96\n",
      "\"1188\"\t94\n",
      "\"1028\"\t93\n",
      "\"1150\"\t93\n",
      "\"1168\"\t93\n",
      "\"1158\"\t90\n",
      "\"1051\"\t86\n",
      "\"1085\"\t86\n",
      "\"1147\"\t86\n",
      "\"1066\"\t82\n",
      "\"1015\"\t79\n",
      "\"1146\"\t79\n",
      "\"1156\"\t75\n",
      "\"1167\"\t72\n",
      "\"1091\"\t69\n",
      "\"1133\"\t69\n",
      "\"1154\"\t67\n",
      "\"1093\"\t65\n",
      "\"1121\"\t63\n",
      "\"1176\"\t63\n",
      "\"1013\"\t61\n",
      "\"1143\"\t60\n",
      "\"1109\"\t59\n",
      "\"1184\"\t57\n",
      "\"1097\"\t56\n",
      "\"1203\"\t55\n",
      "\"1152\"\t52\n",
      "\"1155\"\t52\n",
      "\"1189\"\t51\n",
      "\"1164\"\t49\n",
      "\"1114\"\t48\n",
      "\"1162\"\t48\n",
      "\"1190\"\t48\n",
      "\"1108\"\t47\n",
      "\"1171\"\t47\n",
      "\"1110\"\t46\n",
      "\"1186\"\t46\n",
      "\"1172\"\t45\n",
      "\"1215\"\t45\n",
      "\"1012\"\t44\n",
      "\"1169\"\t44\n",
      "\"1177\"\t43\n",
      "\"1005\"\t42\n",
      "\"1159\"\t41\n",
      "\"1165\"\t38\n",
      "\"1187\"\t38\n",
      "\"1201\"\t38\n",
      "\"1103\"\t36\n",
      "\"1111\"\t36\n",
      "\"1141\"\t36\n",
      "\"1144\"\t36\n",
      "\"1160\"\t36\n",
      "\"1104\"\t35\n",
      "\"1208\"\t34\n",
      "\"1138\"\t33\n",
      "\"1166\"\t33\n",
      "\"1197\"\t32\n",
      "\"1227\"\t32\n",
      "\"1116\"\t31\n",
      "\"1204\"\t30\n",
      "\"1216\"\t30\n",
      "\"1206\"\t29\n",
      "\"1223\"\t29\n",
      "\"1126\"\t27\n",
      "\"1033\"\t26\n",
      "\"1194\"\t26\n",
      "\"1163\"\t25\n",
      "\"1193\"\t25\n",
      "\"1212\"\t25\n",
      "\"1185\"\t24\n",
      "\"1205\"\t24\n",
      "\"1132\"\t23\n",
      "\"1220\"\t23\n",
      "\"1086\"\t22\n",
      "\"1151\"\t21\n",
      "\"1230\"\t21\n",
      "\"1145\"\t20\n",
      "\"1142\"\t19\n",
      "\"1231\"\t19\n",
      "\"1139\"\t18\n",
      "\"1198\"\t18\n",
      "\"1200\"\t18\n",
      "\"1218\"\t18\n",
      "\"1106\"\t16\n",
      "\"1161\"\t16\n",
      "\"1170\"\t16\n",
      "\"1211\"\t16\n",
      "\"1224\"\t16\n",
      "\"1115\"\t15\n",
      "\"1195\"\t15\n",
      "\"1094\"\t14\n",
      "\"1101\"\t14\n",
      "\"1226\"\t14\n",
      "\"1122\"\t13\n",
      "\"1217\"\t13\n",
      "\"1228\"\t13\n",
      "\"1250\"\t13\n",
      "\"1149\"\t12\n",
      "\"1181\"\t12\n",
      "\"1207\"\t12\n",
      "\"1107\"\t11\n",
      "\"1179\"\t11\n",
      "\"1222\"\t11\n",
      "\"1240\"\t11\n",
      "\"1251\"\t11\n",
      "\"1174\"\t10\n",
      "\"1221\"\t10\n",
      "\"1236\"\t10\n",
      "\"1246\"\t10\n",
      "\"1117\"\t9\n",
      "\"1180\"\t9\n",
      "\"1209\"\t9\n",
      "\"1235\"\t9\n",
      "\"1241\"\t9\n",
      "\"1153\"\t8\n",
      "\"1234\"\t8\n",
      "\"1129\"\t7\n",
      "\"1182\"\t7\n",
      "\"1192\"\t7\n",
      "\"1225\"\t7\n",
      "\"1175\"\t6\n",
      "\"1210\"\t5\n",
      "\"1253\"\t5\n",
      "\"1257\"\t5\n",
      "\"1267\"\t5\n",
      "\"1191\"\t4\n",
      "\"1202\"\t4\n",
      "\"1219\"\t4\n",
      "\"1229\"\t4\n",
      "\"1232\"\t4\n",
      "\"1238\"\t4\n",
      "\"1242\"\t4\n",
      "\"1243\"\t4\n",
      "\"1244\"\t4\n",
      "\"1262\"\t4\n",
      "\"1264\"\t4\n",
      "\"1173\"\t3\n",
      "\"1213\"\t3\n",
      "\"1214\"\t3\n",
      "\"1237\"\t3\n",
      "\"1239\"\t3\n",
      "\"1247\"\t3\n",
      "\"1252\"\t3\n",
      "\"1255\"\t3\n",
      "\"1256\"\t3\n",
      "\"1258\"\t3\n",
      "\"1265\"\t3\n",
      "\"1276\"\t3\n",
      "\"1178\"\t2\n",
      "\"1245\"\t2\n",
      "\"1249\"\t2\n",
      "\"1261\"\t2\n",
      "\"1263\"\t2\n",
      "\"1266\"\t2\n",
      "\"1269\"\t2\n",
      "\"1278\"\t2\n",
      "\"1280\"\t2\n",
      "\"1282\"\t2\n",
      "\"1120\"\t1\n",
      "\"1128\"\t1\n",
      "\"1196\"\t1\n",
      "\"1199\"\t1\n",
      "\"1233\"\t1\n",
      "\"1248\"\t1\n",
      "\"1254\"\t1\n",
      "\"1259\"\t1\n",
      "\"1260\"\t1\n",
      "\"1268\"\t1\n",
      "\"1270\"\t1\n",
      "\"1271\"\t1\n",
      "\"1272\"\t1\n",
      "\"1273\"\t1\n",
      "\"1274\"\t1\n",
      "\"1275\"\t1\n",
      "\"1277\"\t1\n",
      "\"1279\"\t1\n",
      "\"1281\"\t1\n",
      "\"1283\"\t1\n",
      "\"1284\"\t1\n",
      "Removing HDFS temp directory hdfs:///user/hadoop/tmp/mrjob/TopFivePages.hadoop.20160610.224207.600433...\n",
      "Removing temp directory /tmp/TopFivePages.hadoop.20160610.224207.600433...\n"
     ]
    }
   ],
   "source": [
    "!python TopFivePages.py -r hadoop ms_logs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Five Output\n",
    "\n",
    "![Top Five](img/topfive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.3 - Execute MRJob from Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'1000', 912)\n",
      "(u'1001', 4451)\n",
      "(u'1002', 749)\n",
      "(u'1003', 2968)\n",
      "(u'1004', 8463)\n",
      "(u'1005', 42)\n",
      "(u'1006', 135)\n",
      "(u'1007', 865)\n",
      "(u'1008', 10836)\n",
      "(u'1009', 4628)\n",
      "(u'1010', 698)\n",
      "(u'1011', 179)\n",
      "(u'1012', 44)\n",
      "(u'1013', 61)\n",
      "(u'1014', 728)\n",
      "(u'1015', 79)\n",
      "(u'1016', 287)\n",
      "(u'1017', 5108)\n",
      "(u'1018', 5330)\n",
      "(u'1019', 111)\n",
      "(u'1020', 1087)\n",
      "(u'1021', 380)\n",
      "(u'1022', 325)\n",
      "(u'1023', 191)\n",
      "(u'1024', 521)\n",
      "(u'1025', 2123)\n",
      "(u'1026', 3220)\n",
      "(u'1027', 507)\n",
      "(u'1028', 93)\n",
      "(u'1029', 132)\n",
      "(u'1030', 1115)\n",
      "(u'1031', 574)\n",
      "(u'1032', 1446)\n",
      "(u'1033', 26)\n",
      "(u'1034', 9383)\n",
      "(u'1035', 1791)\n",
      "(u'1036', 759)\n",
      "(u'1037', 1160)\n",
      "(u'1038', 1110)\n",
      "(u'1039', 345)\n",
      "(u'1040', 1506)\n",
      "(u'1041', 1500)\n",
      "(u'1042', 281)\n",
      "(u'1043', 224)\n",
      "(u'1044', 168)\n",
      "(u'1045', 474)\n",
      "(u'1046', 636)\n",
      "(u'1048', 210)\n",
      "(u'1049', 343)\n",
      "(u'1050', 106)\n",
      "(u'1051', 86)\n",
      "(u'1052', 842)\n",
      "(u'1053', 670)\n",
      "(u'1054', 338)\n",
      "(u'1055', 264)\n",
      "(u'1056', 276)\n",
      "(u'1057', 195)\n",
      "(u'1058', 672)\n",
      "(u'1059', 258)\n",
      "(u'1060', 391)\n",
      "(u'1061', 269)\n",
      "(u'1062', 141)\n",
      "(u'1063', 113)\n",
      "(u'1064', 324)\n",
      "(u'1065', 323)\n",
      "(u'1066', 82)\n",
      "(u'1067', 548)\n",
      "(u'1068', 198)\n",
      "(u'1069', 227)\n",
      "(u'1070', 602)\n",
      "(u'1071', 187)\n",
      "(u'1072', 128)\n",
      "(u'1073', 204)\n",
      "(u'1074', 584)\n",
      "(u'1075', 396)\n",
      "(u'1076', 444)\n",
      "(u'1077', 155)\n",
      "(u'1078', 462)\n",
      "(u'1079', 136)\n",
      "(u'1080', 121)\n",
      "(u'1081', 215)\n",
      "(u'1082', 241)\n",
      "(u'1083', 105)\n",
      "(u'1084', 186)\n",
      "(u'1085', 86)\n",
      "(u'1086', 22)\n",
      "(u'1087', 189)\n",
      "(u'1088', 237)\n",
      "(u'1089', 157)\n",
      "(u'1090', 107)\n",
      "(u'1091', 69)\n",
      "(u'1092', 97)\n",
      "(u'1093', 65)\n",
      "(u'1094', 14)\n",
      "(u'1095', 102)\n",
      "(u'1096', 214)\n",
      "(u'1097', 56)\n",
      "(u'1098', 98)\n",
      "(u'1099', 120)\n",
      "(u'1100', 291)\n",
      "(u'1101', 14)\n",
      "(u'1102', 118)\n",
      "(u'1103', 36)\n",
      "(u'1104', 35)\n",
      "(u'1105', 183)\n",
      "(u'1106', 16)\n",
      "(u'1107', 11)\n",
      "(u'1108', 47)\n",
      "(u'1109', 59)\n",
      "(u'1110', 46)\n",
      "(u'1111', 36)\n",
      "(u'1112', 128)\n",
      "(u'1113', 181)\n",
      "(u'1114', 48)\n",
      "(u'1115', 15)\n",
      "(u'1116', 31)\n",
      "(u'1117', 9)\n",
      "(u'1118', 172)\n",
      "(u'1119', 365)\n",
      "(u'1120', 1)\n",
      "(u'1121', 63)\n",
      "(u'1122', 13)\n",
      "(u'1123', 372)\n",
      "(u'1124', 222)\n",
      "(u'1125', 199)\n",
      "(u'1126', 27)\n",
      "(u'1127', 132)\n",
      "(u'1128', 1)\n",
      "(u'1129', 7)\n",
      "(u'1130', 395)\n",
      "(u'1131', 148)\n",
      "(u'1132', 23)\n",
      "(u'1133', 69)\n",
      "(u'1134', 162)\n",
      "(u'1135', 115)\n",
      "(u'1136', 181)\n",
      "(u'1137', 123)\n",
      "(u'1138', 33)\n",
      "(u'1139', 18)\n",
      "(u'1140', 118)\n",
      "(u'1141', 36)\n",
      "(u'1142', 19)\n",
      "(u'1143', 60)\n",
      "(u'1144', 36)\n",
      "(u'1145', 20)\n",
      "(u'1146', 79)\n",
      "(u'1147', 86)\n",
      "(u'1148', 96)\n",
      "(u'1149', 12)\n",
      "(u'1150', 93)\n",
      "(u'1151', 21)\n",
      "(u'1152', 52)\n",
      "(u'1153', 8)\n",
      "(u'1154', 67)\n",
      "(u'1155', 52)\n",
      "(u'1156', 75)\n",
      "(u'1157', 124)\n",
      "(u'1158', 90)\n",
      "(u'1159', 41)\n",
      "(u'1160', 36)\n",
      "(u'1161', 16)\n",
      "(u'1162', 48)\n",
      "(u'1163', 25)\n",
      "(u'1164', 49)\n",
      "(u'1165', 38)\n",
      "(u'1166', 33)\n",
      "(u'1167', 72)\n",
      "(u'1168', 93)\n",
      "(u'1169', 44)\n",
      "(u'1170', 16)\n",
      "(u'1171', 47)\n",
      "(u'1172', 45)\n",
      "(u'1173', 3)\n",
      "(u'1174', 10)\n",
      "(u'1175', 6)\n",
      "(u'1176', 63)\n",
      "(u'1177', 43)\n",
      "(u'1178', 2)\n",
      "(u'1179', 11)\n",
      "(u'1180', 9)\n",
      "(u'1181', 12)\n",
      "(u'1182', 7)\n",
      "(u'1183', 167)\n",
      "(u'1184', 57)\n",
      "(u'1185', 24)\n",
      "(u'1186', 46)\n",
      "(u'1187', 38)\n",
      "(u'1188', 94)\n",
      "(u'1189', 51)\n",
      "(u'1190', 48)\n",
      "(u'1191', 4)\n",
      "(u'1192', 7)\n",
      "(u'1193', 25)\n",
      "(u'1194', 26)\n",
      "(u'1195', 15)\n",
      "(u'1196', 1)\n",
      "(u'1197', 32)\n",
      "(u'1198', 18)\n",
      "(u'1199', 1)\n",
      "(u'1200', 18)\n",
      "(u'1201', 38)\n",
      "(u'1202', 4)\n",
      "(u'1203', 55)\n",
      "(u'1204', 30)\n",
      "(u'1205', 24)\n",
      "(u'1206', 29)\n",
      "(u'1207', 12)\n",
      "(u'1208', 34)\n",
      "(u'1209', 9)\n",
      "(u'1210', 5)\n",
      "(u'1211', 16)\n",
      "(u'1212', 25)\n",
      "(u'1213', 3)\n",
      "(u'1214', 3)\n",
      "(u'1215', 45)\n",
      "(u'1216', 30)\n",
      "(u'1217', 13)\n",
      "(u'1218', 18)\n",
      "(u'1219', 4)\n",
      "(u'1220', 23)\n",
      "(u'1221', 10)\n",
      "(u'1222', 11)\n",
      "(u'1223', 29)\n",
      "(u'1224', 16)\n",
      "(u'1225', 7)\n",
      "(u'1226', 14)\n",
      "(u'1227', 32)\n",
      "(u'1228', 13)\n",
      "(u'1229', 4)\n",
      "(u'1230', 21)\n",
      "(u'1231', 19)\n",
      "(u'1232', 4)\n",
      "(u'1233', 1)\n",
      "(u'1234', 8)\n",
      "(u'1235', 9)\n",
      "(u'1236', 10)\n",
      "(u'1237', 3)\n",
      "(u'1238', 4)\n",
      "(u'1239', 3)\n",
      "(u'1240', 11)\n",
      "(u'1241', 9)\n",
      "(u'1242', 4)\n",
      "(u'1243', 4)\n",
      "(u'1244', 4)\n",
      "(u'1245', 2)\n",
      "(u'1246', 10)\n",
      "(u'1247', 3)\n",
      "(u'1248', 1)\n",
      "(u'1249', 2)\n",
      "(u'1250', 13)\n",
      "(u'1251', 11)\n",
      "(u'1252', 3)\n",
      "(u'1253', 5)\n",
      "(u'1254', 1)\n",
      "(u'1255', 3)\n",
      "(u'1256', 3)\n",
      "(u'1257', 5)\n",
      "(u'1258', 3)\n",
      "(u'1259', 1)\n",
      "(u'1260', 1)\n",
      "(u'1261', 2)\n",
      "(u'1262', 4)\n",
      "(u'1263', 2)\n",
      "(u'1264', 4)\n",
      "(u'1265', 3)\n",
      "(u'1266', 2)\n",
      "(u'1267', 5)\n",
      "(u'1268', 1)\n",
      "(u'1269', 2)\n",
      "(u'1270', 1)\n",
      "(u'1271', 1)\n",
      "(u'1272', 1)\n",
      "(u'1273', 1)\n",
      "(u'1274', 1)\n",
      "(u'1275', 1)\n",
      "(u'1276', 3)\n",
      "(u'1277', 1)\n",
      "(u'1278', 2)\n",
      "(u'1279', 1)\n",
      "(u'1280', 2)\n",
      "(u'1281', 1)\n",
      "(u'1282', 2)\n",
      "(u'1283', 1)\n",
      "(u'1284', 1)\n",
      "(u'1295', 716)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from TopFivePages import MRGetTopFive\n",
    "mr_job = MRGetTopFive(args=['ms_logs.txt'])\n",
    "\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print (mr_job.parse_output_line(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.4 - Most Frequent Visitor\n",
    "\n",
    "Find the most frequent visitor of each page using MrJob and the output of 4.2  (i.e., transformed log file). In this output please include the webpage URL, webpageID and Visitor ID.\n",
    "\n",
    "The first task is to create the master list of web pages and URL from the raw web log data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4 - Create master file of web page URLs from raw log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting generate_url.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile generate_url.py\n",
    "#!/usr/bin/python\n",
    "## generate_url.py\n",
    "## Author: James Gray\n",
    "## Description: create master list of URL's from raw weblog data \n",
    "\n",
    "# open CSV file\n",
    "from csv import reader\n",
    "with open('anonymous-msweb.data','rb') as f:\n",
    "    data=f.readlines()\n",
    "    \n",
    "for i in reader(data):\n",
    "    if i[0]=='A':\n",
    "        print i[1]+','+i[3]+','+i[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Master list of web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287,International AutoRoute,/autoroute\r\n",
      "1288,library,/library\r\n",
      "1289,Master Chef Product Information,/masterchef\r\n",
      "1297,Central America,/centroam\r\n",
      "1215,For Developers Only Info,/developer\r\n",
      "1279,Multimedia Golf,/msgolf\r\n",
      "1239,Microsoft Consulting,/msconsult\r\n",
      "1282,home,/home\r\n",
      "1251,Reference Support,/referencesupport\r\n",
      "1121,Microsoft Magazine,/magazine\r\n",
      "1083,MS Access Support,/msaccesssupport\r\n",
      "1145,Visual Fox Pro Support,/vfoxprosupport\r\n",
      "1276,Visual Test Support,/vtestsupport\r\n",
      "1200,Benelux Region,/benelux\r\n",
      "1259,controls,/controls\r\n"
     ]
    }
   ],
   "source": [
    "!chmod a+x generate_url.py\n",
    "!python generate_url.py > msft_urls.txt\n",
    "!cat msft_urls.txt | head -15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4 - MR Job Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Use this to make sure we reload the MrJob code when we make changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MostFrequentVisitor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MostFrequentVisitor.py\n",
    "#!/usr/bin/python\n",
    "## mostfrequentvisitor.py\n",
    "## Author: James Gray\n",
    "## Description: calculate the most frequent visitor of each web page. Produces output: URL, webpageID, visitorID\n",
    "\n",
    "# Example data format\n",
    "# V, webpageID,count,C,visitorID\n",
    "# V,1000,1,C,10001\n",
    "# V,1001,1,C,10001\n",
    "# V,1002,1,C,10001\n",
    "\n",
    "import csv\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "def csv_readline(line):\n",
    "    \"\"\"return a list of strings for each row\"\"\"\n",
    "    for row in csv.reader([line]):\n",
    "        return row\n",
    "\n",
    "class MRFrequentVisitor(MRJob):\n",
    "\n",
    "    def mapper_page_views(self, line_no, line):\n",
    "        \"\"\"Extracts the page that was visited and the visitor id\"\"\"\n",
    "        row = csv_readline(line)\n",
    "        # emit KV pairs of webpageID, visitorID\n",
    "        if row[0] == 'V': \n",
    "            yield row[1],row[4]\n",
    "    \n",
    "    def reducer_load_urls(self):\n",
    "        \"\"\"Load file of page URLs into reducer memory\"\"\"\n",
    "        with open('msft_urls.txt','rb') as f:\n",
    "            urls=csv.reader(f.readlines())\n",
    "        self.url_dict={}\n",
    "        for i in urls:\n",
    "            #Populuate URLs into a dictionary\n",
    "            self.url_dict[int(i[0])]=i[2]\n",
    "\n",
    "    def reducer_sum_views_by_visitor(self, vroots, visitor):\n",
    "        \"\"\"Summarizes visitor counts for each page, \n",
    "        yields one record per page with the visitor responsible for  \n",
    "        the most views on that page\"\"\"\n",
    "        \n",
    "        # use a Counter to store the number of page views by user\n",
    "        visitors=Counter()\n",
    "        for i in visitor:\n",
    "            visitors[i]+=1 #Aggregate page views for all visitors\n",
    "        output= max(visitors.iteritems(), key=itemgetter(1))[0] #Find visitor responsible for the most page views\n",
    "        yield (str(vroots)),(output,visitors[output],self.url_dict[int(vroots)])\n",
    "   \n",
    "    def steps(self):\n",
    "        return [MRStep(mapper=self.mapper_page_views,\n",
    "                        reducer_init=self.reducer_load_urls,\n",
    "                        reducer=self.reducer_sum_views_by_visitor)]\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    FreqVisitor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4 - MRJob Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== RESULTS ==========\n",
      "PAGE | VISITOR ID | # VISITS | PAGE URL \n",
      "----------------------------------------\n",
      "1000  36585        1          /regwiz\n",
      "1001  23995        1          /support\n",
      "1002  35235        1          /athome\n",
      "1003  22469        1          /kb\n",
      "1004  35540        1          /search\n",
      "1005  10004        1          /norge\n",
      "1006  27495        1          /misc\n",
      "1007  19492        1          /ie_intl\n",
      "1008  35236        1          /msdownload\n",
      "1009  22504        1          /windows\n",
      "1010  20915        1          /vbasic\n",
      "1011  40152        1          /officedev\n",
      "1012  37811        1          /outlookdev\n",
      "1013  32727        1          /vbasicsupport\n",
      "1014  20914        1          /officefreestuff\n",
      "1015  16662        1          /msexcel\n",
      "1016  35542        1          /excel\n",
      "1017  37091        1          /products\n",
      "1018  34620        1          /isapi\n",
      "1019  16765        1          /mspowerpoint\n",
      "1020  39325        1          /msdn\n",
      "1021  35234        1          /visualc\n",
      "1022  15906        1          /truetype\n",
      "1023  16079        1          /spain\n",
      "1024  20447        1          /iis\n",
      "1025  35234        1          /gallery\n",
      "1026  23990        1          /sitebuilder\n",
      "1027  35234        1          /intdev\n",
      "1028  11191        1          /oledev\n",
      "1029  33083        1          /clipgallerylive\n",
      "1030  20447        1          /ntserver\n",
      "1031  22505        1          /msoffice\n",
      "1032  35542        1          /games\n",
      "1033  38870        1          /logostore\n",
      "1034  35540        1          /ie\n",
      "1035  22469        1          /windowssupport\n",
      "1036  22505        1          /organizations\n",
      "1037  19490        1          /windows95\n",
      "1038  36585        1          /sbnmember\n",
      "1039  26948        1          /isp\n",
      "1040  16078        1          /office\n",
      "1041  35234        1          /workshop\n",
      "1042  18312        1          /vstudio\n",
      "1043  33738        1          /smallbiz\n",
      "1044  40224        1          /mediadev\n",
      "1045  20917        1          /netmeeting\n",
      "1046  18496        1          /iesupport\n",
      "1048  33083        1          /publisher\n",
      "1049  33329        1          /supportnet\n",
      "1050  30757        1          /macoffice\n",
      "1051  32702        1          /scheduleplus\n",
      "1052  20914        1          /word\n",
      "1053  36585        1          /visualj\n",
      "1054  23200        1          /exchange\n",
      "1055  39791        1          /kids\n",
      "1056  27954        1          /sports\n",
      "1057  39792        1          /powerpoint\n",
      "1058  19490        1          /referral\n",
      "1059  19263        1          /sverige\n",
      "1060  20914        1          /msword\n",
      "1061  25070        1          /promo\n",
      "1062  36585        1          /msaccess\n",
      "1063  39793        1          /intranet\n",
      "1064  42285        1          /activeplatform\n",
      "1065  20175        1          /java\n",
      "1066  40977        1          /musicproducer\n",
      "1067  33738        1          /frontpage\n",
      "1068  19548        1          /vbscript\n",
      "1069  32702        1          /windowsce\n",
      "1070  35234        1          /activex\n",
      "1071  35237        1          /automap\n",
      "1072  35708        1          /vinterdev\n",
      "1073  26095        1          /taiwan\n",
      "1074  11520        1          /ntworkstation\n",
      "1075  35541        1          /jobs\n",
      "1076  33328        1          /ntwkssupport\n",
      "1077  40554        1          /msofficesupport\n",
      "1078  14174        1          /ntserversupport\n",
      "1079  40557        1          /australia\n",
      "1080  11825        1          /brasil\n",
      "1081  36585        1          /accessdev\n",
      "1082  36581        1          /access\n",
      "1083  25263        1          /msaccesssupport\n",
      "1084  18312        1          /uk\n",
      "1085  25179        1          /exchangesupport\n",
      "1086  27590        1          /oem\n",
      "1087  14344        1          /proxy\n",
      "1088  42285        1          /outlook\n",
      "1089  40152        1          /officereference\n",
      "1090  20842        1          /gamessupport\n",
      "1091  13971        1          /hwdev\n",
      "1092  35231        1          /vfoxpro\n",
      "1093  18053        1          /vba\n",
      "1094  16325        1          /mshome\n",
      "1095  39791        1          /catalog\n",
      "1096  19490        1          /mspress\n",
      "1097  18646        1          /latam\n",
      "1098  21485        1          /devonly\n",
      "1099  15453        1          /cio\n",
      "1100  25071        1          /education\n",
      "1101  20067        1          /oledb\n",
      "1102  30059        1          /homeessentials\n",
      "1103  10168        1          /works\n",
      "1104  18889        1          /hk\n",
      "1105  30323        1          /france\n",
      "1106  22258        1          /cze\n",
      "1107  17654        1          /slovakia\n",
      "1108  36176        1          /teammanager\n",
      "1109  22777        1          /technet\n",
      "1110  20931        1          /mastering\n",
      "1111  35353        1          /ssafe\n",
      "1112  19263        1          /canada\n",
      "1113  26781        1          /security\n",
      "1114  27596        1          /servad\n",
      "1115  14980        1          /hun\n",
      "1116  27868        1          /switzerland\n",
      "1117  41101        1          /sidewinder\n",
      "1118  14347        1          /sql\n",
      "1119  33738        1          /corpinfo\n",
      "1120  10241        1          /switch\n",
      "1121  41018        1          /magazine\n",
      "1122  25185        1          /mindshare\n",
      "1123  22506        1          /germany\n",
      "1124  30187        1          /industry\n",
      "1125  27594        1          /imagecomposer\n",
      "1126  10272        1          /mediamanager\n",
      "1127  39790        1          /netshow\n",
      "1128  10286        1          /msf\n",
      "1129  20067        1          /ado\n",
      "1130  18495        1          /syspro\n",
      "1131  40053        1          /moneyzone\n",
      "1132  20613        1          /msmoneysupport\n",
      "1133  32647        1          /frontpagesupport\n",
      "1134  16071        1          /backoffice\n",
      "1135  33243        1          /mswordsupport\n",
      "1136  33329        1          /usa\n",
      "1137  16470        1          /mscorp\n",
      "1138  17452        1          /mind\n",
      "1139  23476        1          /k-12\n",
      "1140  33245        1          /netherlands\n",
      "1141  41073        1          /europe\n",
      "1142  40197        1          /southafrica\n",
      "1143  42286        1          /workshoop\n",
      "1144  41640        1          /devnews\n",
      "1145  33490        1          /vfoxprosupport\n",
      "1146  20674        1          /msp\n",
      "1147  38899        1          /msft\n",
      "1148  33081        1          /channel_resources\n",
      "1149  19852        1          /adc\n",
      "1150  11191        1          /infoserv\n",
      "1151  32892        1          /mspowerpointsupport\n",
      "1152  34046        1          /rus\n",
      "1153  18646        1          /venezuela\n",
      "1154  27030        1          /project\n",
      "1155  33364        1          /sidewalk\n",
      "1156  41311        1          /powered\n",
      "1157  33241        1          /win32dev\n",
      "1158  29597        1          /imedia\n",
      "1159  35319        1          /transaction\n",
      "1160  39694        1          /visualcsupport\n",
      "1161  42263        1          /workssupport\n",
      "1162  42285        1          /infoservsupport\n",
      "1163  14851        1          /opentype\n",
      "1164  24181        1          /smsmgmt\n",
      "1165  40203        1          /poland\n",
      "1166  25153        1          /mexico\n",
      "1167  13853        1          /hwtest\n",
      "1168  22500        1          /salesinfo\n",
      "1169  22773        1          /msproject\n",
      "1170  15223        1          /mail\n",
      "1171  26782        1          /merchant\n",
      "1172  32769        1          /belgium\n",
      "1173  10842        1          /moli\n",
      "1174  28627        1          /nz\n",
      "1175  18943        1          /msprojectsupport\n",
      "1176  31408        1          /jscript\n",
      "1177  19240        1          /events\n",
      "1178  31500        1          /msdownload.\n",
      "1179  18041        1          /colombia\n",
      "1180  28362        1          /slovenija\n",
      "1181  14189        1          /kidssupport\n",
      "1182  11090        1          /fortran\n",
      "1183  19718        1          /italy\n",
      "1184  35032        1          /msexcelsupport\n",
      "1185  21645        1          /sna\n",
      "1186  40197        1          /college\n",
      "1187  32493        1          /odbc\n",
      "1188  11190        1          /korea\n",
      "1189  14240        1          /internet\n",
      "1190  29884        1          /repository\n",
      "1191  11331        1          /management\n",
      "1192  11359        1          /visualjsupport\n",
      "1193  40539        1          /offdevsupport\n",
      "1194  18981        1          /china\n",
      "1195  26790        1          /portugal\n",
      "1196  11431        1          /ie40\n",
      "1197  42285        1          /sqlsupport\n",
      "1198  14963        1          /pictureit\n",
      "1199  11644        1          /feedback\n",
      "1200  13636        1          /benelux\n",
      "1201  16073        1          /hardware\n",
      "1202  41172        1          /advtech\n",
      "1203  25260        1          /danmark\n",
      "1204  23205        1          /msscheduleplus\n",
      "1205  40153        1          /hardwaresupport\n",
      "1206  35045        1          /select\n",
      "1207  21353        1          /icp\n",
      "1208  40662        1          /israel\n",
      "1209  34593        1          /turkey\n",
      "1210  20598        1          /snasupport\n",
      "1211  23461        1          /smsmgmtsupport\n",
      "1212  19367        1          /worldwide\n",
      "1213  12472        1          /corporate_solutions\n",
      "1214  12515        1          /finserv\n",
      "1215  40224        1          /developer\n",
      "1216  32725        1          /vrml\n",
      "1217  38711        1          /ireland\n",
      "1218  15722        1          /publishersupport\n",
      "1219  14961        1          /ads\n",
      "1220  27804        1          /macofficesupport\n",
      "1221  19514        1          /mstv\n",
      "1222  14138        1          /msofc\n",
      "1223  13837        1          /finland\n",
      "1224  14522        1          /atec\n",
      "1225  17980        1          /piracy\n",
      "1226  32170        1          /msschedplussupport\n",
      "1227  18603        1          /argentina\n",
      "1228  40428        1          /vtest\n",
      "1229  26913        1          /uruguay\n",
      "1230  31314        1          /mailsupport\n",
      "1231  41626        1          /win32devsupport\n",
      "1232  13926        1          /standards\n",
      "1233  14363        1          /vbscripts\n",
      "1234  42626        1          /off97cat\n",
      "1235  30514        1          /onlineeval\n",
      "1236  14738        1          /globaldev\n",
      "1237  14764        1          /devdays\n",
      "1238  26885        1          /exceldev\n",
      "1239  38020        1          /msconsult\n",
      "1240  21961        1          /thailand\n",
      "1241  19165        1          /india\n",
      "1242  16289        1          /msgarden\n",
      "1243  20439        1          /usability\n",
      "1244  38662        1          /devwire\n",
      "1245  31934        1          /ofc\n",
      "1246  25085        1          /gamesdev\n",
      "1247  30024        1          /wineguide\n",
      "1248  18347        1          /softimage\n",
      "1249  41914        1          /fortransupport\n",
      "1250  23902        1          /middleeast\n",
      "1251  18941        1          /referencesupport\n",
      "1252  23781        1          /giving\n",
      "1253  31926        1          /worddev\n",
      "1254  20190        1          /ie3\n",
      "1255  22674        1          /msmq\n",
      "1256  20832        1          /sia\n",
      "1257  25717        1          /devvideos\n",
      "1258  30514        1          /peru\n",
      "1259  21424        1          /controls\n",
      "1260  21894        1          /trial\n",
      "1261  22485        1          /diyguide\n",
      "1262  37425        1          /chile\n",
      "1263  27503        1          /services\n",
      "1264  40427        1          /se_partners\n",
      "1265  39038        1          /ssafesupport\n",
      "1266  26815        1          /licenses\n",
      "1267  27482        1          /caribbean\n",
      "1268  27503        1          /javascript\n",
      "1269  41054        1          /business\n",
      "1270  28493        1          /developr\n",
      "1271  28493        1          /mdsn\n",
      "1272  28493        1          /softlib\n",
      "1273  28493        1          /mdn\n",
      "1274  28493        1          /pdc\n",
      "1275  28903        1          /security.\n",
      "1276  40810        1          /vtestsupport\n",
      "1277  30111        1          /stream\n",
      "1278  30460        1          /hed\n",
      "1279  31062        1          /msgolf\n",
      "1280  41643        1          /music\n",
      "1281  37099        1          /intellimouse\n",
      "1282  41244        1          /home\n",
      "1283  41033        1          /cinemania\n",
      "1284  41108        1          /partner\n",
      "1295  19490        1          /train_cert\n"
     ]
    }
   ],
   "source": [
    "#HW 4.4 - Driver Function\n",
    "from MostFrequentVisitor import MRFrequentVisitor\n",
    "import csv\n",
    "\n",
    "def run_4_4():\n",
    "    mr_job = MRFrequentVisitor(args=['ms_logs.txt','--file','msft_urls.txt'])\n",
    "    with mr_job.make_runner() as runner:\n",
    "        runner.run()\n",
    "        print \"PAGE | VISITOR ID | # VISITS | WEB PAGE URL \"\n",
    "        print \"----------------------------------------\"\n",
    "        for line in runner.stream_output():\n",
    "            output=mr_job.parse_output_line(line)\n",
    "            print str(output[0])+'  '+str(output[1][0])+'        '+str(output[1][1])+'          '+str(output[1][2])\n",
    "\n",
    "run_4_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.4 - Output\n",
    "\n",
    "![output](img/mostfrequent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.5 Clustering Tweet Dataset\n",
    "\n",
    "Here you will use a different dataset consisting of word-frequency distributions \n",
    "for 1,000 Twitter users. These Twitter users use language in very different ways,\n",
    "and were classified by hand according to the criteria:\n",
    "\n",
    "0: Human, where only basic human-human communication is observed.\n",
    "\n",
    "1: Cyborg, where language is primarily borrowed from other sources\n",
    "(e.g., jobs listings, classifieds postings, advertisements, etc...).\n",
    "\n",
    "2: Robot, where language is formulaically derived from unrelated sources\n",
    "(e.g., weather/seismology, police/fire event logs, etc...).\n",
    "\n",
    "3: Spammer, where language is replicated to high multiplicity\n",
    "(e.g., celebrity obsessions, personal promotion, etc... )\n",
    "\n",
    "Check out the preprints of  recent research,\n",
    "which spawned this dataset:\n",
    "\n",
    "http://arxiv.org/abs/1505.04342\n",
    "http://arxiv.org/abs/1508.01843\n",
    "\n",
    "The main data lie in the accompanying file:\n",
    "\n",
    "topUsers_Apr-Jul_2014_1000-words.txt\n",
    "\n",
    "and are of the form:\n",
    "\n",
    "USERID,CODE,TOTAL,WORD1_COUNT,WORD2_COUNT,...\n",
    ".\n",
    ".\n",
    "\n",
    "where\n",
    "\n",
    "USERID = unique user identifier\n",
    "CODE = 0/1/2/3 class code\n",
    "TOTAL = sum of the word counts\n",
    "\n",
    "Using this data, you will implement a 1000-dimensional K-means algorithm in MrJob on the users\n",
    "by their 1000-dimensional word stripes/vectors using several \n",
    "centroid initializations and values of K.\n",
    "\n",
    "Note that each \"point\" is a user as represented by 1000 words, and that\n",
    "word-frequency distributions are generally heavy-tailed power-laws\n",
    "(often called Zipf distributions), and are very rare in the larger class\n",
    "of discrete, random distributions. For each user you will have to normalize\n",
    "by its \"TOTAL\" column. Try several parameterizations and initializations:\n",
    "\n",
    "(A) K=4 uniform random centroid-distributions over the 1000 words (generate 1000 random numbers and normalize the vectors)\n",
    "(B) K=2 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "(C) K=4 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "(D) K=4 \"trained\" centroids, determined by the sums across the classes. Use use the \n",
    "(row-normalized) class-level aggregates as 'trained' starting centroids (i.e., the training is already done for you!).\n",
    "Note that you do not have to compute the aggregated distribution or the \n",
    "class-aggregated distributions, which are rows in the auxiliary file:\n",
    "\n",
    "topUsers_Apr-Jul_2014_1000-words_summaries.txt\n",
    "\n",
    "Row 1: Words\n",
    "Row 2: Aggregated distribution across all classes\n",
    "Row 3-6 class-aggregated distributions for clases 0-3\n",
    "For (A),  we select 4 users randomly from a uniform distribution [1,...,1,000]\n",
    "For (B), (C), and (D)  you will have to use data from the auxiliary file: \n",
    "\n",
    "topUsers_Apr-Jul_2014_1000-words_summaries.txt\n",
    "\n",
    "This file contains 5 special word-frequency distributions:\n",
    "\n",
    "(1) The 1000-user-wide aggregate, which you will perturb for initializations\n",
    "in parts (B) and (C), and\n",
    "\n",
    "(2-5) The 4 class-level aggregates for each of the user-type classes (0/1/2/3)\n",
    "\n",
    "\n",
    "In parts (B) and (C), you will have to perturb the 1000-user aggregate \n",
    "(after initially normalizing by its sum, which is also provided).\n",
    "So if in (B) you want to create 2 perturbations of the aggregate, start\n",
    "with (1), normalize, and generate 1000 random numbers uniformly \n",
    "from the unit interval (0,1) twice (for two centroids), using:\n",
    "\n",
    "from numpy import random\n",
    "numbers = random.sample(1000)\n",
    "\n",
    "Take these 1000 numbers and add them (component-wise) to the 1000-user aggregate,\n",
    "and then renormalize to obtain one of your aggregate-perturbed initial centroids.\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "## Generate random initial centroids around the global aggregate\n",
    "## Part (B) and (C) of this question\n",
    "###################################################################################\n",
    "def startCentroidsBC(k):\n",
    "    counter = 0\n",
    "    for line in open(\"topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter == 2:        \n",
    "            data = re.split(\",\",line)\n",
    "            globalAggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "        counter += 1\n",
    "    ## perturb the global aggregate for the four initializations    \n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        rndpoints = random.sample(1000)\n",
    "        peturpoints = [rndpoints[n]/10+globalAggregate[n] for n in range(1000)]\n",
    "        centroids.append(peturpoints)\n",
    "        total = 0\n",
    "        for j in range(len(centroids[i])):\n",
    "            total += centroids[i][j]\n",
    "        for j in range(len(centroids[i])):\n",
    "            centroids[i][j] = centroids[i][j]/total\n",
    "    return centroids\n",
    "\n",
    "\n",
    "\n",
    "——\n",
    "For experiments A, B, C and D and iterate until a threshold (try 0.001) is reached.\n",
    "After convergence, print out a summary of the classes present in each cluster.\n",
    "In particular, report the composition as measured by the total\n",
    "portion of each class type (0-3) contained in each cluster,\n",
    "and discuss your findings and any differences in outcomes across parts A-D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.5 - Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.5 - Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.5 - Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4.5 - Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4.6 (OPTIONAL) Scaleable K-MEANS++ \n",
    "\n",
    "Over half a century old and showing no signs of aging,\n",
    "k-means remains one of the most popular data processing\n",
    "algorithms. As is well-known, a proper initialization\n",
    "of k-means is crucial for obtaining a good final solution.\n",
    "The recently proposed k-means++ initialization algorithm\n",
    "achieves this, obtaining an initial set of centers that is provably\n",
    "close to the optimum solution. A major downside of the\n",
    "k-means++ is its inherent sequential nature, which limits its\n",
    "applicability to massive data: one must make k passes over\n",
    "the data to find a good initial set of centers. The paper listed below \n",
    "shows how to drastically reduce the number of passes needed\n",
    "to obtain, in parallel, a good initialization. This is unlike\n",
    "prevailing efforts on parallelizing k-means that have mostly\n",
    "focused on the post-initialization phases of k-means. The \n",
    "proposed initialization algorithm k-means||\n",
    "obtains a nearly optimal solution after a logarithmic number\n",
    "of passes; the paper also shows that in practice a constant\n",
    "number of passes suffices. Experimental evaluation on realworld\n",
    "large-scale data demonstrates that k-means|| outperforms\n",
    "k-means++ in both sequential and parallel settings.\n",
    "\n",
    "Read the following paper entitled \"Scaleable K-MEANS++\" located at:\n",
    "\n",
    "http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf \n",
    "\n",
    "In MrJob, implement K-MEANS|| and compare with a random initializtion when used in \n",
    "conjunction with the kmeans algorithm as an initialization step for the 2D  dataset \n",
    "generated using code in the following notebook:\n",
    "\n",
    "https://www.dropbox.com/s/lbzwmyv0d8rocfq/MrJobKmeans.ipynb?dl=0\n",
    "\n",
    "Plot the initialation centroids and the centroid trajectory as the K-MEANS|| algorithms iterates. \n",
    "Repeat this for a random initalization (i.e., pick a training vector at random for each inital centroid)\n",
    "of the kmeans algorithm. Comment on the trajectories of both algorithms.\n",
    "Report on the number passes over the training data, and time required to run both  clustering algorithms.\n",
    "Also report the rand index score for both algorithms and comment on your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.6.1 \n",
    "\n",
    "Apply your implementation of K-MEANS|| to the dataset  in HW 4.5 and compare to the a \n",
    "random initalization (i.e., pick a training vector at random for each inital centroid)of the kmeans algorithm.\n",
    "Report on the number passes over the training data, and time required to run all  clustering algorithms. \n",
    "Also report the rand index score for both algorithms and comment on your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4.7 (OPTIONAL) Canopy Clustering\n",
    "\n",
    "An alternative way to intialize the k-means algorithm is the  canopy clustering. The canopy clustering \n",
    "algorithm is an unsupervised pre-clustering algorithm introduced by Andrew McCallum, Kamal Nigam and \n",
    "Lyle Ungar in 2000. It is often used as preprocessing step for the K-means algorithm or the \n",
    "Hierarchical clustering algorithm. It is intended to speed up clustering operations on large data sets, \n",
    "where using another algorithm directly may be impractical due to the size of the data set.\n",
    "\n",
    "For more details on the Canopy Clustering algorithm see:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Canopy_clustering_algorithm\n",
    "\n",
    "Plot the initialation centroids and the centroid trajectory as the Canopy Clustering based K-MEANS algorithm iterates. \n",
    "Repeat this for a random initalization (i.e., pick a training vector at random for each inital centroid)\n",
    "of the kmeans algorithm. Comment on the trajectories of both algorithms.\n",
    "Report on the number passes over the training data, and time required to run both  clustering algorithms.\n",
    "Also report the rand index score for both algorithms and comment on your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4.7.1 \n",
    "\n",
    "Apply your implementation Canopy Clustering based K-MEANS algorithm to the dataset  in HW 4.5 and compare to the a \n",
    "random initalization (i.e., pick a training vector at random for each inital centroid)of the kmeans algorithm.\n",
    "Report on the number passes over the training data, and time required to run both  clustering algorithms. \n",
    "Also report the rand index score for both algorithms and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
